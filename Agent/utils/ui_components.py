"""
UIç»„ä»¶æ¨¡å—ï¼ŒåŒ…å«æ‰€æœ‰Streamlit UIæ¸²æŸ“é€»è¾‘
"""
import streamlit as st
import pandas as pd
from datetime import datetime
from typing import Tuple, List, Any
import logging
from utils.document_processor import DocumentProcessor
from services.vector_store import VectorStoreService
from langchain.schema import Document
from config.settings import AVAILABLE_EMBEDDING_MODELS

logger = logging.getLogger(__name__)

class UIComponents:
    """UIç»„ä»¶ç±»ï¼Œå°è£…äº†æ‰€æœ‰Streamlit UIæ¸²æŸ“é€»è¾‘"""
    
    # 1.æ¸²æŸ“æ¨¡å‹é€‰æ‹©ç»„ä»¶
    @staticmethod
    def render_model_selection(available_models: List[str], current_model: str, embedding_models: List[str], current_embedding_model: str) -> Tuple[str, str]:
        """
        available_models - å¯ç”¨æ¨¡å‹åˆ—è¡¨
        current_model - å½“å‰é€‰ä¸­çš„æ¨¡å‹
        embedding_models - å¯ç”¨åµŒå…¥æ¨¡å‹åˆ—è¡¨
        current_embedding_model - å½“å‰é€‰ä¸­çš„åµŒå…¥æ¨¡å‹

        @return (ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹, ç”¨æˆ·é€‰æ‹©çš„åµŒå…¥æ¨¡å‹)
        """
        st.sidebar.header("âš™ï¸ è®¾ç½®")
        
        new_model = st.sidebar.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=available_models,
            index=available_models.index(current_model) if current_model in available_models else 0,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹"
        )
        
        new_embedding_model = st.sidebar.selectbox(
            "åµŒå…¥æ¨¡å‹",
            options=embedding_models,
            index=embedding_models.index(current_embedding_model) if current_embedding_model in embedding_models else 0,
            help="é€‰æ‹©ç”¨äºæ–‡æ¡£åµŒå…¥çš„æ¨¡å‹"
        )
        
        return new_model, new_embedding_model
    

    # 2. æ¸²æŸ“RAGè®¾ç½®ç»„ä»¶
    @staticmethod
    def render_rag_settings(rag_enabled: bool, similarity_threshold: float, default_threshold: float) -> Tuple[bool, float]:
        """
        rag_enabled - æ˜¯å¦å¯ç”¨RAG
        similarity_threshold - ç›¸ä¼¼åº¦é˜ˆå€¼
        default_threshold - é»˜è®¤ç›¸ä¼¼åº¦é˜ˆå€¼

        @return (æ˜¯å¦å¯ç”¨RAG, ç›¸ä¼¼åº¦é˜ˆå€¼)
        """
        st.sidebar.subheader("RAGè®¾ç½®")
        
        new_rag_enabled = st.sidebar.checkbox(
            "å¯ç”¨RAG",
            value=rag_enabled,
            help="å¯ç”¨æ£€ç´¢å¢å¼ºç”ŸæˆåŠŸèƒ½ï¼Œä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£å¢å¼ºå›ç­”"
        )
        
        new_similarity_threshold = st.sidebar.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.0,
            max_value=1.0,
            value=similarity_threshold,
            step=0.05,
            help="è°ƒæ•´æ£€ç´¢ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå€¼è¶Šé«˜è¦æ±‚åŒ¹é…åº¦è¶Šç²¾ç¡®"
        )
        
        # å°†é‡ç½®ç›¸ä¼¼åº¦é˜ˆå€¼æŒ‰é’®æ ·å¼æ›´æ”¹ä¸ºå®¹å™¨å®½åº¦
        if st.sidebar.button("é‡ç½®ç›¸ä¼¼åº¦é˜ˆå€¼", use_container_width=True):
            new_similarity_threshold = default_threshold
            
        return new_rag_enabled, new_similarity_threshold
    

    # 3. æ¸²æŸ“èŠå¤©ç»Ÿè®¡ä¿¡æ¯
    @staticmethod
    def render_chat_stats(chat_history):
        """
        chat_history - èŠå¤©å†å²ç®¡ç†å™¨
        """
        st.sidebar.header("ğŸ’¬ å¯¹è¯å†å²")
        stats = chat_history.get_stats()
        st.sidebar.info(f"æ€»å¯¹è¯æ•°: {stats['total_messages']} ç”¨æˆ·æ¶ˆæ¯: {stats['user_messages']}")
        
        if st.sidebar.button("ğŸ“¥ å¯¼å‡ºå¯¹è¯å†å²", use_container_width=True):
            csv = chat_history.export_to_csv()
            if csv:
                st.sidebar.download_button(
                    label="ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv,
                    file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        if st.sidebar.button("âœ¨ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            chat_history.clear_history()
            st.rerun()


    # 4. æ¸²æŸ“æ–‡æ¡£ä¸Šä¼ ç»„ä»¶
    @staticmethod
    def render_document_upload(
        document_processor: DocumentProcessor,
        vector_store: VectorStoreService,
        processed_documents: List[str]
    ) -> Tuple[List[Document], VectorStoreService]:
        """
        document_processor - æ–‡æ¡£å¤„ç†å™¨
        vector_store - å‘é‡å­˜å‚¨æœåŠ¡
        processed_documents - å·²å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨

        @return (all_docs, vector_store)
        """
        ##withç»“æŸï¼Œexpanderè‡ªåŠ¨å…³é—­
        with st.expander("ğŸ“ ä¸Šä¼ RAGæ–‡æ¡£", expanded=not bool(processed_documents)):
            uploaded_files = st.file_uploader(
                "ä¸Šä¼ PDFã€TXTæ–‡ä»¶", 
                type=["pdf", "txt"],
                accept_multiple_files=True
            )
            
            if not vector_store.vector_store:   ##ä»–åˆå§‹å€¼ä¸ºNoneï¼Œä»£è¡¨è¿˜æ²¡æœ‰å¯ç”¨æ–‡æ¡£
                st.warning("âš ï¸ è¯·åœ¨ä¾§è¾¹æ é…ç½®å‘é‡å­˜å‚¨ä»¥å¯ç”¨æ–‡æ¡£å¤„ç†ã€‚")
            
            all_docs = []
            if uploaded_files:
                if st.button("å¤„ç†æ–‡æ¡£"):
                    with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                        for uploaded_file in uploaded_files:
                            if uploaded_file.name not in processed_documents:
                                try:    ##ä¸Šé¢è¯´æ˜ä¸Šä¼ æ–‡ä»¶åä¸åœ¨å·²å¤„ç†æ–‡æ¡£å°±æ‰§è¡Œä¸‹é¢
                                    # ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ–‡ä»¶ç±»å‹
                                    result = document_processor.process_file(uploaded_file)
                                    
                                    if isinstance(result, list):
                                        # ç»“æœæ˜¯Documentåˆ—è¡¨(PDFæ–‡æ¡£)
                                        all_docs.extend(result)
                                    else:
                                        # ç»“æœæ˜¯æ–‡æœ¬å†…å®¹(TXTã€DOCXç­‰)
                                        doc = Document(
                                            page_content=result, 
                                            metadata={"source": uploaded_file.name}
                                        )
                                        all_docs.append(doc)
                                    
                                    processed_documents.append(uploaded_file.name)
                                    st.success(f"âœ… å·²å¤„ç†: {uploaded_file.name}")
                                except Exception as e:
                                    st.error(f"âŒ å¤„ç†å¤±è´¥: {uploaded_file.name} - {str(e)}")
                            else:
                                st.warning(f"âš ï¸ å·²å­˜åœ¨: {uploaded_file.name}")
                
                if all_docs:
                    with st.spinner("æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•..."):
                        vector_store.vector_store = vector_store.create_vector_store(all_docs)
            
            # æ˜¾ç¤ºå·²å¤„ç†æ–‡æ¡£åˆ—è¡¨
            if processed_documents:
                st.subheader("å·²å¤„ç†æ–‡æ¡£")
                for doc in processed_documents:
                    st.markdown(f"- {doc}")
                
                if st.button("æ¸…é™¤æ‰€æœ‰æ–‡æ¡£"):
                    with st.spinner("æ­£åœ¨æ¸…é™¤å‘é‡ç´¢å¼•..."):
                        vector_store.clear_index()
                        processed_documents.clear()
                    st.success("âœ… æ‰€æœ‰æ–‡æ¡£å·²æ¸…é™¤")
                    st.rerun()
            
            return all_docs, vector_store


    # 5. æ¸²æŸ“èŠå¤©å†å²
    @staticmethod
    def render_chat_history(chat_history):
        """
        chat_history - èŠå¤©å†å²ç®¡ç†å™¨
        """
        for message in chat_history.history:
            role = message.get('role', '')
            content = message.get('content', '')
            
            if role == "assistant_think":
                with st.expander("ğŸ’¡ æŸ¥çœ‹æ¨ç†è¿‡ç¨‹ <think> ... </think>"):
                    st.markdown(content)
            elif role == "retrieved_doc":
                with st.expander(f"ğŸ” æŸ¥çœ‹æœ¬æ¬¡å¬å›çš„æ–‡æ¡£å—", expanded=False):
                    if isinstance(content, list):
                        for idx, doc in enumerate(content, 1):
                            st.markdown(f"**æ–‡æ¡£å—{idx}:**\n{doc}")
                    else:
                        st.markdown(content)
            else:
                with st.chat_message(role):
                    st.write(content) 